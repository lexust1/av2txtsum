1
00:00:00,160 --> 00:00:09,800
 ♪

2
00:00:09,800 --> 00:00:13,600
 Welcome to IBM Think 2023.

3
00:00:13,600 --> 00:00:17,520
 ♪

4
00:00:17,520 --> 00:00:21,020
 AI-generated art.

5
00:00:21,020 --> 00:00:23,820
 AI-generated songs.

6
00:00:23,820 --> 00:00:25,740
 AI, what is that?

7
00:00:25,740 --> 00:00:27,860
 It sure is a lot of fun.

8
00:00:27,860 --> 00:00:30,980
 But when foundation models are applied to big business,

9
00:00:30,980 --> 00:00:33,360
 well, you need to think bigger.

10
00:00:33,360 --> 00:00:37,420
 Because AI in business needs to be held to a higher standard.

11
00:00:37,420 --> 00:00:40,780
 Built to be trusted, secured, and adaptable.

12
00:00:40,780 --> 00:00:44,460
 This isn't simple automation that is only trained to do one thing.

13
00:00:44,460 --> 00:00:48,840
 This is AI that is built and focused to work across your organization.

14
00:00:48,840 --> 00:00:50,920
 This isn't committing to a single system.

15
00:00:50,920 --> 00:00:55,020
 This is hybrid-ready AI that can scale across your systems.

16
00:00:55,020 --> 00:00:57,480
 This isn't wondering where an answer came from.

17
00:00:57,480 --> 00:01:00,980
 This is AI that can show its work.

18
00:01:00,980 --> 00:01:03,240
 When you build AI into the core of your business,

19
00:01:03,240 --> 00:01:06,020
 you can go so much further.

20
00:01:06,020 --> 00:01:07,540
 This is more than AI.

21
00:01:07,540 --> 00:01:11,500
 This is AI for business.

22
00:01:11,500 --> 00:01:14,460
 Let's create.

23
00:01:14,460 --> 00:01:18,080
 Please welcome Senior Vice President and Director

24
00:01:18,080 --> 00:01:22,000
 of Research, IBM, Dr. Dario Gil.

25
00:01:22,000 --> 00:01:27,100
 Hello.

26
00:01:27,100 --> 00:01:28,400
 Welcome.

27
00:01:28,400 --> 00:01:28,900
 Welcome.

28
00:01:28,900 --> 00:01:30,820
 The last session of "Think."

29
00:01:30,820 --> 00:01:33,740
 And I understand some of you even had a drink.

30
00:01:33,740 --> 00:01:35,440
 How special.

31
00:01:35,440 --> 00:01:39,400
 So I hope you've enjoyed the last two days with us.

32
00:01:39,400 --> 00:01:43,920
 And what an incredible year it has been for AI.

33
00:01:43,920 --> 00:01:48,320
 You can really feel the change that is happening all around us.

34
00:01:48,320 --> 00:01:52,420
 And it's just not denying that the pace of this technology

35
00:01:52,420 --> 00:01:56,980
 continues to be exhilarating, and that its implications

36
00:01:56,980 --> 00:02:01,520
 are now so clear for all to see around the globe.

37
00:02:01,520 --> 00:02:04,320
 I'm just fascinated by AI.

38
00:02:04,320 --> 00:02:08,400
 And as a technologist, this level of excitement

39
00:02:08,400 --> 00:02:12,820
 really comes about only maybe once or twice every decade.

40
00:02:12,820 --> 00:02:16,860
 And I'm just thrilled to see all the possibilities

41
00:02:16,860 --> 00:02:19,100
 that this technology is going to enable.

42
00:02:19,100 --> 00:02:22,720
 Because it's really going to impact every industry,

43
00:02:22,720 --> 00:02:26,360
 from customer care to transforming data centers

44
00:02:26,360 --> 00:02:30,180
 and logistics to medicine to manufacturing to energy

45
00:02:30,180 --> 00:02:33,220
 to the automotive industry to aerospace, communications,

46
00:02:33,220 --> 00:02:34,420
 you name it.

47
00:02:34,420 --> 00:02:37,820
 It's really going to impact every one of our businesses

48
00:02:37,820 --> 00:02:40,940
 and really touch every aspect of our lives.

49
00:02:40,940 --> 00:02:42,300
 So it's really exciting.

50
00:02:42,300 --> 00:02:45,920
 And while sometimes the pace of this technology

51
00:02:45,920 --> 00:02:50,660
 can feel daunting and scary, the opportunities

52
00:02:50,660 --> 00:02:54,040
 to harness foundation models and generative AI

53
00:02:54,040 --> 00:02:55,980
 with proper governance-- the opportunity

54
00:02:55,980 --> 00:02:57,060
 is going to be immense.

55
00:02:57,060 --> 00:02:59,080
 The opportunities are immense.

56
00:02:59,080 --> 00:03:02,740
 The emergence of foundation models and generative AI

57
00:03:02,740 --> 00:03:05,360
 is really a defining moment.

58
00:03:05,360 --> 00:03:08,620
 And we need to recognize its importance.

59
00:03:08,620 --> 00:03:11,420
 We need to capture the moment.

60
00:03:11,420 --> 00:03:15,620
 And my advice is, don't be just an AI user.

61
00:03:15,620 --> 00:03:18,100
 Be an AI value creator.

62
00:03:18,100 --> 00:03:19,700
 Just think about it.

63
00:03:19,700 --> 00:03:24,820
 As an AI user, you are limited to just prompting someone else's

64
00:03:24,820 --> 00:03:25,860
 AI model.

65
00:03:25,860 --> 00:03:27,660
 It's not your model.

66
00:03:27,660 --> 00:03:31,580
 You have no control over the model or the data.

67
00:03:31,580 --> 00:03:33,540
 Just think carefully about whether that's

68
00:03:33,540 --> 00:03:36,400
 the world you want to live in.

69
00:03:36,400 --> 00:03:39,320
 As an AI value creator, on the other hand,

70
00:03:39,320 --> 00:03:41,680
 you have multiple entry points.

71
00:03:41,680 --> 00:03:46,000
 You can bring your own data and AI models to Watson X

72
00:03:46,000 --> 00:03:50,720
 or choose from a library of tools and technologies.

73
00:03:50,720 --> 00:03:54,280
 You can train or influence training if you want.

74
00:03:54,280 --> 00:03:55,740
 You can tune.

75
00:03:55,740 --> 00:03:59,760
 You can have transparency and control over the governing data

76
00:03:59,760 --> 00:04:01,380
 and AI models.

77
00:04:01,380 --> 00:04:03,340
 You can prompt it, too.

78
00:04:03,340 --> 00:04:08,080
 Instead of only one models, you will have a family of models.

79
00:04:08,080 --> 00:04:11,240
 And through this creative process, you can improve them.

80
00:04:11,240 --> 00:04:14,260
 And you can make them your own, your own models.

81
00:04:14,260 --> 00:04:18,380
 Foundation models that are trained with your data

82
00:04:18,380 --> 00:04:22,100
 will become your most valuable asset.

83
00:04:22,100 --> 00:04:25,620
 And as a value creator, you will own that.

84
00:04:25,620 --> 00:04:27,260
 You can control the value that they

85
00:04:27,260 --> 00:04:29,660
 will create for your business.

86
00:04:29,660 --> 00:04:31,980
 So don't outsource that.

87
00:04:31,980 --> 00:04:36,720
 You can simply control your destiny with foundation models.

88
00:04:36,720 --> 00:04:40,500
 So let me show you how we become and allow

89
00:04:40,500 --> 00:04:44,680
 you to become a value creator with Watson X.

90
00:04:44,680 --> 00:04:48,380
 Watson X is our new integrated data and AI platform.

91
00:04:48,380 --> 00:04:51,680
 It consists of three primary parts.

92
00:04:51,680 --> 00:04:54,300
 First, WatsonX.data.

93
00:04:54,300 --> 00:04:55,500
 It is our massive, curated, data

94
00:04:55,500 --> 00:05:00,200
 repository that is ready to be tapped to train and fine-tune

95
00:05:00,200 --> 00:05:05,220
 models with state-of-the-art data management system.

96
00:05:05,220 --> 00:05:06,920
 WatsonX.ai.

97
00:05:06,920 --> 00:05:11,060
 This is an enterprise studio to train, validate, tune,

98
00:05:11,060 --> 00:05:14,160
 and deploy traditional machine learning and foundation

99
00:05:14,160 --> 00:05:17,880
 models that provide generative capabilities.

100
00:05:17,880 --> 00:05:20,360
 And WatsonX.governance.

101
00:05:20,360 --> 00:05:25,380
 This is a powerful set of tools to ensure your AI is executing

102
00:05:25,380 --> 00:05:27,400
 responsibly.

103
00:05:27,400 --> 00:05:31,800
 WatsonX.data, WatsonX.ai, WatsonX.governance.

104
00:05:31,800 --> 00:05:35,540
 They work together seamlessly throughout the entire lifecycle

105
00:05:35,540 --> 00:05:37,740
 of foundation models.

106
00:05:37,740 --> 00:05:42,060
 And true to our commitment to hybrid cloud architectures,

107
00:05:42,060 --> 00:05:46,260
 WatsonX is built on top of Red Hat OpenShift.

108
00:05:46,260 --> 00:05:48,620
 Not only does it provide seamless integration

109
00:05:48,620 --> 00:05:55,260
 of WatsonX components, it allows you to access and deploy your AI work

110
00:05:55,260 --> 00:06:00,500
 workloads in any IT environment, no matter where they are located.

111
00:06:00,500 --> 00:06:04,720
 WatsonX.data is the AI platform for value creators.

112
00:06:04,720 --> 00:06:10,180
 Look, I don't need to tell you that deploying these technologies

113
00:06:10,180 --> 00:06:12,760
 is not easy at the enterprise level.

114
00:06:12,760 --> 00:06:14,680
 But the platform changes that.

115
00:06:14,680 --> 00:06:19,880
 So let's take a look now of how an entire AI workflow, end-to-end,

116
00:06:19,880 --> 00:06:21,740
 works in the platform.

117
00:06:21,740 --> 00:06:25,140
 The lifecycle consists of preparing our data,

118
00:06:25,140 --> 00:06:29,040
 using it to train the model, validate the model, tune it,

119
00:06:29,040 --> 00:06:32,360
 and deploy in applications and solutions.

120
00:06:32,360 --> 00:06:34,600
 So let's start with data preparation.

121
00:06:34,600 --> 00:06:36,460
 So say you're a data scientist and want

122
00:06:36,460 --> 00:06:39,780
 to access the data that is in a public cloud, some that

123
00:06:39,780 --> 00:06:44,520
 is on-prem, some that may be in another external database,

124
00:06:44,520 --> 00:06:47,180
 or on a public cloud, a second one,

125
00:06:47,180 --> 00:06:51,080
 or anywhere else outside your hybrid cloud platform.

126
00:06:51,080 --> 00:06:53,640
 So you access the platform from your laptop

127
00:06:53,640 --> 00:06:55,020
 and invoke WatsonX.data.

128
00:06:55,020 --> 00:06:59,520
 It establishes the necessary connections between the data

129
00:06:59,520 --> 00:07:03,060
 sources so you can access the data easily.

130
00:07:03,060 --> 00:07:07,660
 We've been building our IBM data pile, combining raw data collected

131
00:07:07,660 --> 00:07:11,640
 from public sources with IBM proprietary data.

132
00:07:11,640 --> 00:07:13,940
 We're bringing data from different domains--

133
00:07:13,940 --> 00:07:20,180
 the internet, code, academic sources, enterprise, and more.

134
00:07:20,180 --> 00:07:24,900
 We have used WatsonX.data to collect petabytes of data

135
00:07:24,900 --> 00:07:30,580
 across dozens of domains to produce trillions of tokens

136
00:07:30,580 --> 00:07:33,980
 that we can use to train foundation models.

137
00:07:33,980 --> 00:07:37,340
 And besides the raw data and our proprietary data,

138
00:07:37,340 --> 00:07:40,480
 we allow clients to bring their own data

139
00:07:40,480 --> 00:07:43,400
 to enrich and improve their purpose-built foundation

140
00:07:43,400 --> 00:07:44,460
 models.

141
00:07:44,460 --> 00:07:49,100
 It is all stored in dot data with granular metadata that

142
00:07:49,100 --> 00:07:53,820
 provides traceable governance for each file or document.

143
00:07:53,820 --> 00:07:54,780
 So now we take--

144
00:07:54,780 --> 00:07:58,180
 --this, and we move to filter and process the data.

145
00:07:58,180 --> 00:08:02,260
 First, we identify the provenance and the ID of the data.

146
00:08:02,260 --> 00:08:04,320
 Then we need to categorize it.

147
00:08:04,320 --> 00:08:09,180
 We classify it, for example, in a pile for different languages--

148
00:08:09,180 --> 00:08:12,560
 let's say English, Spanish, German, and so on--

149
00:08:12,560 --> 00:08:15,340
 a pile of code data that we then separate by programming

150
00:08:15,340 --> 00:08:19,260
 language-- Java, Ansible, COBOL, and so on--

151
00:08:19,260 --> 00:08:22,120
 and any other category that we have.

152
00:08:22,120 --> 00:08:24,120
 Now we filter it.

153
00:08:24,120 --> 00:08:24,660
 We do analytics.

154
00:08:24,660 --> 00:08:27,760
 We do analytics and get rid of duplicated data.

155
00:08:27,760 --> 00:08:31,940
 Now we identify hate, abuse, and profanity in the data,

156
00:08:31,940 --> 00:08:33,720
 and we remove it.

157
00:08:33,720 --> 00:08:37,200
 We filter it for private information, licensing

158
00:08:37,200 --> 00:08:40,100
 constraints, and data quality.

159
00:08:40,100 --> 00:08:42,420
 By annotating, we allow data scientists

160
00:08:42,420 --> 00:08:48,120
 to determine the right thresholds for their filtering.

161
00:08:48,120 --> 00:08:50,220
 Having done all of that, the pile

162
00:08:50,220 --> 00:08:52,820
 is now ready for the next step.

163
00:08:52,820 --> 00:08:54,540
 We version and tag the data.

164
00:08:54,540 --> 00:08:59,660
 Each data set, after being filtered and preprocessed,

165
00:08:59,660 --> 00:09:02,240
 receives a data card.

166
00:09:02,240 --> 00:09:05,560
 The data card has the name and the version of the pile,

167
00:09:05,560 --> 00:09:08,980
 specifies its content, and filters

168
00:09:08,980 --> 00:09:12,680
 that have been applied to it, and any other relevant content

169
00:09:12,680 --> 00:09:18,280
 to make it easy to manage and track different choices that

170
00:09:18,280 --> 00:09:20,520
 of the work and the right subsets of the data

171
00:09:20,520 --> 00:09:24,420
 that we've used to develop the foundation models.

172
00:09:24,420 --> 00:09:26,500
 We can have multiple data piles.

173
00:09:26,500 --> 00:09:29,440
 They coexist in dot data, and access

174
00:09:29,440 --> 00:09:32,380
 to different versions of data for different purpose

175
00:09:32,380 --> 00:09:34,400
 is managed seamlessly.

176
00:09:34,400 --> 00:09:36,540
 So we're now ready to take the pile

177
00:09:36,540 --> 00:09:38,460
 and start training our model.

178
00:09:38,460 --> 00:09:41,840
 This is step two in our AI workflow.

179
00:09:41,840 --> 00:09:45,420
 So we move from dot data to dot AI,

180
00:09:45,420 --> 00:09:48,700
 and start by picking a model architecture from the five

181
00:09:48,700 --> 00:09:51,400
 families that IBM provides.

182
00:09:51,400 --> 00:09:54,300
 These are bedrocks of models, and they're

183
00:09:54,300 --> 00:09:58,540
 changed from encoder-only, encoder-decoder, decoder-only,

184
00:09:58,540 --> 00:10:00,820
 and other novel architectures.

185
00:10:00,820 --> 00:10:04,180
 So let's pick the encoder-decoder sandstone

186
00:10:04,180 --> 00:10:09,220
 to train the model, and pick a target data pile version

187
00:10:09,220 --> 00:10:11,980
 from the piles that is in dot data.

188
00:10:11,980 --> 00:10:14,860
 Dot AI allows training with computing resources

189
00:10:14,860 --> 00:10:16,800
 across the hybrid cloud.

190
00:10:16,800 --> 00:10:20,000
 In this case, it runs on IBM Vela.

191
00:10:20,000 --> 00:10:24,180
 Vela is a first-of-a-kind cloud-native AI supercomputer

192
00:10:24,180 --> 00:10:25,960
 that we built last year.

193
00:10:25,960 --> 00:10:27,840
 It gives you bare-metal performance

194
00:10:27,840 --> 00:10:30,520
 in the cloud with a virtualization overhead

195
00:10:30,520 --> 00:10:32,980
 that is less than 5%.

196
00:10:32,980 --> 00:10:36,360
 And we're making it available as a service.

197
00:10:36,360 --> 00:10:40,140
 Watson X dot AI auto-scales the resources for the training

198
00:10:40,140 --> 00:10:41,520
 being done.

199
00:10:41,520 --> 00:10:43,300
 And the first thing that we need to do

200
00:10:43,300 --> 00:10:47,000
 is to tokenize the data according to the requirements

201
00:10:47,000 --> 00:10:48,940
 of the model.

202
00:10:48,940 --> 00:10:51,940
 So we first query the data using the version ID

203
00:10:51,940 --> 00:10:54,060
 for the pile we want to use.

204
00:10:54,060 --> 00:10:56,700
 That materializes a copy of the data

205
00:10:56,700 --> 00:11:00,240
 set on Vela for tokenization.

206
00:11:00,240 --> 00:11:02,540
 What this means is that, for example,

207
00:11:02,540 --> 00:11:04,520
 if we're building a large language model,

208
00:11:04,520 --> 00:11:08,520
 the sentences in the data are broken into tokens.

209
00:11:08,520 --> 00:11:12,520
 And this process can create trillions of them.

210
00:11:12,520 --> 00:11:15,180
 And we use the tokens to train the model.

211
00:11:15,180 --> 00:11:18,800
 Now, training is a very complex and time-consuming task.

212
00:11:18,800 --> 00:11:23,120
 It can require dozens, hundreds, even thousands of GPUs,

213
00:11:23,120 --> 00:11:23,940
 and can take days.

214
00:11:23,940 --> 00:11:28,040
 It can take days, weeks, and even months.

215
00:11:28,040 --> 00:11:30,120
 Training in Watson dot AI takes advantage

216
00:11:30,120 --> 00:11:33,180
 of the best open-source technology out there

217
00:11:33,180 --> 00:11:36,060
 to simplify the user experience.

218
00:11:36,060 --> 00:11:40,320
 Built on CodeFlare, using PyTorch and Ray,

219
00:11:40,320 --> 00:11:43,140
 it also integrates Hugging Face to bring you

220
00:11:43,140 --> 00:11:46,620
 a rich variety of open formats.

221
00:11:46,620 --> 00:11:51,000
 Once training is done, the model is ready for validation.

222
00:11:51,000 --> 00:11:53,820
 So for each model we train, we run an extensive set

223
00:11:53,820 --> 00:11:56,560
 of benchmarks to evaluate the model quality

224
00:11:56,560 --> 00:12:00,000
 across a wide range of metrics.

225
00:12:00,000 --> 00:12:02,340
 Once the model passes all the thresholds

226
00:12:02,340 --> 00:12:05,700
 across the benchmarks, it is packaged and marked

227
00:12:05,700 --> 00:12:07,500
 as ready for use.

228
00:12:07,500 --> 00:12:10,320
 For each model, we create a model card

229
00:12:10,320 --> 00:12:14,060
 that lists all the details of the model.

230
00:12:14,060 --> 00:12:15,780
 We will have many different models

231
00:12:15,780 --> 00:12:19,420
 trained on different piles with different target goals.

232
00:12:19,420 --> 00:12:22,940
 Next, we go to Watson X dot governance to combine the data

233
00:12:22,940 --> 00:12:23,700
 card.

234
00:12:23,700 --> 00:12:26,280
 This is a model card that has the detailed provenance

235
00:12:26,280 --> 00:12:29,880
 information for the data pile that was used for training

236
00:12:29,880 --> 00:12:33,840
 with the model card that has the detailed information on how

237
00:12:33,840 --> 00:12:36,700
 the model was trained and validated.

238
00:12:36,700 --> 00:12:40,380
 Together, they form a fact sheet.

239
00:12:40,380 --> 00:12:44,460
 This fact sheet is cataloged in dot governance

240
00:12:44,460 --> 00:12:46,920
 and all the other fact sheets for all the models

241
00:12:46,920 --> 00:12:49,740
 that we have available for use.

242
00:12:49,740 --> 00:12:53,580
 Now, let's go on to tune the model that we just created.

243
00:12:53,580 --> 00:12:55,400
 What we mean by that is to adapt it

244
00:12:55,400 --> 00:12:58,220
 to new downstream tasks, which is

245
00:12:58,220 --> 00:13:02,040
 the basis for the large productivity gains that

246
00:13:02,040 --> 00:13:04,920
 is afforded by foundation models.

247
00:13:04,920 --> 00:13:07,740
 So say, in this case, you're a different persona.

248
00:13:07,740 --> 00:13:09,760
 You're the application developer.

249
00:13:09,760 --> 00:13:11,800
 So you can access Watson X dot AI

250
00:13:11,800 --> 00:13:16,160
 and start by picking a model from the catalog to work with.

251
00:13:16,160 --> 00:13:18,800
 We have a family of IBM models specialized

252
00:13:18,800 --> 00:13:20,380
 for different domains.

253
00:13:20,380 --> 00:13:23,460
 But we also have a rich set of open models

254
00:13:23,460 --> 00:13:25,940
 and training models because we believe

255
00:13:25,940 --> 00:13:29,060
 in the creativity of the global AI community

256
00:13:29,060 --> 00:13:31,920
 and in the diversity of models it offers.

257
00:13:31,920 --> 00:13:34,800
 And we want to bring that to you.

258
00:13:34,800 --> 00:13:40,180
 In this case, we pick Sandstone dot 3B from the IBM language

259
00:13:40,180 --> 00:13:43,920
 models, which is the model that we just trained.

260
00:13:43,920 --> 00:13:47,520
 We set up the options for tuning, the tuning approach.

261
00:13:47,520 --> 00:13:50,640
 We pick summarization as an example

262
00:13:50,640 --> 00:13:53,340
 as the base model to use.

263
00:13:53,340 --> 00:13:56,840
 We can access and use business proprietary data

264
00:13:56,840 --> 00:14:02,420
 to tune the base model and for the task that we choose,

265
00:14:02,420 --> 00:14:05,800
 whether that business data is located

266
00:14:05,800 --> 00:14:07,940
 anywhere in the hybrid cloud platform.

267
00:14:07,940 --> 00:14:11,040
 So now we send prompts and tuning data.

268
00:14:11,040 --> 00:14:14,780
 And that's used to tune the model in dot AI.

269
00:14:14,780 --> 00:14:18,960
 You get the outcome of the prompt on the model.

270
00:14:18,960 --> 00:14:21,960
 This process happens back and forth, back and forth

271
00:14:21,960 --> 00:14:23,220
 many times.

272
00:14:23,220 --> 00:14:28,680
 And in the end, you end up with a set of ideal prompts to use.

273
00:14:28,680 --> 00:14:32,600
 The model is now specialized and ready to deploy.

274
00:14:32,600 --> 00:14:36,160
 This is the final step in our AI workflow.

275
00:14:36,160 --> 00:14:39,600
 The application where you want to use the foundation model

276
00:14:39,600 --> 00:14:41,860
 can live in the public cloud.

277
00:14:41,860 --> 00:14:45,100
 It can live on-prem or on the edge.

278
00:14:45,100 --> 00:14:48,000
 And you can really deploy and run foundation models

279
00:14:48,000 --> 00:14:51,400
 efficiently wherever you need them.

280
00:14:51,400 --> 00:14:53,100
 And the deployed model can be used

281
00:14:53,100 --> 00:14:55,140
 in many different applications.

282
00:14:55,140 --> 00:14:58,000
 So for example, we've embedded foundation models

283
00:14:58,000 --> 00:14:59,820
 in Watson Assistant.

284
00:14:59,820 --> 00:15:01,740
 For text generation in Assistant,

285
00:15:01,740 --> 00:15:05,920
 you describe the topic that you want the Assistant to handle.

286
00:15:05,920 --> 00:15:09,280
 And it generates the corresponding conversational

287
00:15:09,280 --> 00:15:10,660
 flow.

288
00:15:10,660 --> 00:15:15,440
 We have an inference stack to scale the serving of the model

289
00:15:15,440 --> 00:15:17,020
 in applications.

290
00:15:17,020 --> 00:15:19,040
 It consists of state-of-the-art technology

291
00:15:19,040 --> 00:15:22,980
 that has been field tested for scalable model serving.

292
00:15:22,980 --> 00:15:27,420
 This is how WatsonX allows us to go from data to a model that

293
00:15:27,420 --> 00:15:31,100
 is trusted, governed, deployed and ready to serve,

294
00:15:31,100 --> 00:15:35,700
 and how we can scale that model to different applications.

295
00:15:35,700 --> 00:15:39,180
 Once models are deployed, we continuously monitor them

296
00:15:39,180 --> 00:15:44,180
 and update them in both .data and in .ai.

297
00:15:44,180 --> 00:15:49,460
 We call this constant process or data and model factory.

298
00:15:49,460 --> 00:15:52,860
 As WatsonX.governance monitors the models,

299
00:15:52,860 --> 00:15:57,740
 it is any change that may impact how the model can be used

300
00:15:57,740 --> 00:16:01,820
 or performs be driven because we have new data that can be

301
00:16:01,820 --> 00:16:06,100
 leveraged, or there's a change in some regulation or law

302
00:16:06,100 --> 00:16:07,900
 or data licensing.

303
00:16:07,900 --> 00:16:12,180
 Any change detected by the .governance process guides

304
00:16:12,180 --> 00:16:17,400
 and process the update to both the data and the model.

305
00:16:17,400 --> 00:16:19,360
 The idea of the model factory is that that

306
00:16:19,360 --> 00:16:22,740
 is central to solid and proper governance of AI.

307
00:16:22,740 --> 00:16:26,980
 Now, all of these updates need to happen without disrupting

308
00:16:26,980 --> 00:16:29,680
 the underlying applications that are leveraging

309
00:16:29,680 --> 00:16:31,620
 the foundation models.

310
00:16:31,620 --> 00:16:35,180
 And this data and model factory is in production today.

311
00:16:35,180 --> 00:16:39,060
 We have already produced over 20 models across modalities

312
00:16:39,060 --> 00:16:43,400
 like language, code, geospatial, and chemistry,

313
00:16:43,400 --> 00:16:47,660
 and spanning different sizes of models from hundreds of millions

314
00:16:47,660 --> 00:16:51,240
 to billions of parameters.

315
00:16:51,240 --> 00:16:52,620
 We've infused these foundations

316
00:16:52,620 --> 00:16:57,500
 models into IBM products, Red Hat products, and/or partners

317
00:16:57,500 --> 00:16:58,660
 products.

318
00:16:58,660 --> 00:17:01,460
 At IBM, over 12 foundation models

319
00:17:01,460 --> 00:17:04,980
 are powering our IBM NLP library, which

320
00:17:04,980 --> 00:17:10,940
 is used in over 15 IBM products and is available to ISVs.

321
00:17:10,940 --> 00:17:14,720
 Granite models trained over code are part of IBM Watson Code

322
00:17:14,720 --> 00:17:18,580
 Assistant, which has been applied in the Red Hat Ansible

323
00:17:18,580 --> 00:17:20,420
 automation platform.

324
00:17:20,420 --> 00:17:22,500
 And as you heard earlier in this event,

325
00:17:22,500 --> 00:17:26,960
 SAP has partnered with us and is infusing foundation models

326
00:17:26,960 --> 00:17:28,960
 into their solutions.

327
00:17:28,960 --> 00:17:33,940
 So Watson X is really ready for you to create value with AI.

328
00:17:33,940 --> 00:17:36,820
 Now, to maximize what you can do and the innovations

329
00:17:36,820 --> 00:17:39,040
 at your disposal, we believe that you

330
00:17:39,040 --> 00:17:42,040
 should bet on community.

331
00:17:42,040 --> 00:17:46,940
 Because the truth is, one model will not rule them all.

332
00:17:46,940 --> 00:17:49,620
 And with the innovations and models

333
00:17:49,620 --> 00:17:52,380
 that it develops, the open community

334
00:17:52,380 --> 00:17:57,620
 is supercharging the value that you will be able to create.

335
00:17:57,620 --> 00:18:00,860
 To be true to our belief in the diversity

336
00:18:00,860 --> 00:18:04,180
 and the creativity of the open AI community,

337
00:18:04,180 --> 00:18:08,380
 we're proud to announce our new partnership with Hugging Face.

338
00:18:08,380 --> 00:18:11,040
 So let's invite to the stage co-founder and CEO

339
00:18:11,040 --> 00:18:14,320
 of Hugging Face, Clem DeLong.

340
00:18:14,320 --> 00:18:14,820
 Clem.

341
00:18:14,820 --> 00:18:18,760
 Hey, Dario.

342
00:18:18,760 --> 00:18:21,420
 Clem, thanks for having me.

343
00:18:21,420 --> 00:18:22,260
 First of all, welcome.

344
00:18:22,260 --> 00:18:23,180
 Welcome to IBM Think.

345
00:18:23,180 --> 00:18:25,280
 We're just delighted to have you here.

346
00:18:25,280 --> 00:18:27,480
 So let's begin by, tell us a little bit about yourself

347
00:18:27,480 --> 00:18:29,600
 and how and when you got interested in AI.

348
00:18:29,600 --> 00:18:31,540
 And how did Hugging Face get started?

349
00:18:31,540 --> 00:18:33,580
 Yeah, thanks so much for having me.

350
00:18:33,580 --> 00:18:37,380
 I actually started in AI almost 15 years ago.

351
00:18:37,380 --> 00:18:40,500
 I look at the room at the time we couldn't have filled it.

352
00:18:40,500 --> 00:18:45,260
 Maybe it would have been 1%, 2% of the room at most.

353
00:18:45,260 --> 00:18:48,200
 As a matter of fact, we weren't even calling it AI at the time.

354
00:18:48,200 --> 00:18:50,500
 We were calling it computer vision.

355
00:18:50,500 --> 00:18:52,140
 I was working at a French company.

356
00:18:52,140 --> 00:18:56,460
 I'm French, as you can hear from my accent.

357
00:18:56,460 --> 00:19:00,320
 And we were doing computer vision on device, on mobile.

358
00:19:00,320 --> 00:19:03,340
 The company went on to get acquired by Google after,

359
00:19:03,340 --> 00:19:07,960
 but I never lost my passion and excitement for AI.

360
00:19:07,960 --> 00:19:12,040
 So seven years ago, with my co-founders, Julie and Thomas,

361
00:19:12,040 --> 00:19:15,640
 we gathered around this passion for AI

362
00:19:15,640 --> 00:19:18,940
 and started Hugging Face, what you see on my t-shirt,

363
00:19:18,940 --> 00:19:20,060
 basically.

364
00:19:20,060 --> 00:19:22,020
 We started with something completely different.

365
00:19:22,020 --> 00:19:26,620
 We worked on conversational AI for three years.

366
00:19:26,620 --> 00:19:30,220
 And as it sometimes happens for startups,

367
00:19:30,220 --> 00:19:33,180
 the underlying platform and technology

368
00:19:33,180 --> 00:19:37,240
 ended up more useful than the end product.

369
00:19:37,240 --> 00:19:40,320
 When we started to release part of it on GitHub,

370
00:19:40,320 --> 00:19:44,500
 we started to see open source contributors joining us.

371
00:19:44,500 --> 00:19:49,300
 We started to see scientists sharing models on the platform,

372
00:19:49,300 --> 00:19:51,900
 leading to what Hugging Face is today.

373
00:19:51,900 --> 00:19:56,320
 So I mentioned the power and the creativity

374
00:19:56,320 --> 00:19:59,380
 of the open community creating an AI.

375
00:19:59,380 --> 00:20:01,580
 Just share with us some statistics.

376
00:20:01,580 --> 00:20:03,020
 How big is it?

377
00:20:03,020 --> 00:20:05,060
 How much energy is there in that community?

378
00:20:05,060 --> 00:20:07,520
 And how much should we expect in that creativity

379
00:20:07,520 --> 00:20:09,100
 available to all of us?

380
00:20:09,100 --> 00:20:13,860
 Yeah, the energy in open source AI is insane these days.

381
00:20:13,860 --> 00:20:16,640
 Just a few weeks ago, I was in San Francisco.

382
00:20:16,640 --> 00:20:19,480
 I tweeted that I would be around and that we

383
00:20:19,480 --> 00:20:21,780
 could do some sort of a small get-together.

384
00:20:21,780 --> 00:20:25,660
 And I said, OK, let's do it together for open source AI

385
00:20:25,660 --> 00:20:27,020
 people.

386
00:20:27,020 --> 00:20:31,020
 We thought we would get maybe a few dozen, a few hundred people.

387
00:20:31,020 --> 00:20:35,540
 And the more the days came, the more people ended up joining.

388
00:20:35,540 --> 00:20:38,700
 We had to change locations three times to something.

389
00:20:38,700 --> 00:20:43,260
 At the end, almost as big as that, we had 5,000 people.

390
00:20:43,260 --> 00:20:46,660
 People started calling it the Woodstock of AI.

391
00:20:46,660 --> 00:20:49,020
 So that's just an example.

392
00:20:49,020 --> 00:20:51,660
 We're competing with that as the Woodstock, Woodstock

393
00:20:51,660 --> 00:20:52,580
 of AI.

394
00:20:52,580 --> 00:20:54,880
 We're competing with that as the Woodstock of AI.

395
00:20:54,880 --> 00:20:57,420
 We're competing with that as the Woodstock, Woodstock of AI.

396
00:20:57,420 --> 00:21:00,540
 We're competing with that as the Woodstock, Woodstock of AI.

397
00:21:00,540 --> 00:21:03,380
 So we're competing with that as the Woodstock, Woodstock of AI.

398
00:21:03,380 --> 00:21:06,660
 So we're competing with that as the Woodstock, Woodstock of AI.

399
00:21:06,660 --> 00:21:09,820
 So we're competing with that as the Woodstock, Woodstock of AI.

400
00:21:09,820 --> 00:21:12,900
 So we're competing with that as the Woodstock, Woodstock of AI.

401
00:21:12,900 --> 00:21:16,380
 So we're competing with that as the Woodstock, Woodstock of AI.

402
00:21:16,380 --> 00:21:19,900
 We're competing with that as the Woodstock, Woodstock of AI.

403
00:21:19,900 --> 00:21:20,900
 So we're competing with that as the Woodstock, Woodstock of AI.

404
00:21:20,900 --> 00:21:21,000
 So we're competing with that as the Woodstock, Woodstock of AI.

405
00:21:21,000 --> 00:21:21,020
 We're competing with that as the Woodstock, Woodstock of AI.

406
00:21:21,020 --> 00:21:21,040
 So we're competing with that as the Woodstock, Woodstock of AI.

407
00:21:21,040 --> 00:21:21,040
 So we're competing with that as the Woodstock, Woodstock of AI.

408
00:21:21,040 --> 00:21:21,040
 So we're competing with that as the Woodstock, Woodstock of AI.

409
00:21:21,040 --> 00:21:21,060
 So we're competing with that as the Woodstock, Woodstock of AI.

410
00:21:21,060 --> 00:21:21,080
 So we're competing with that as the Woodstock, Woodstock of AI.

411
00:21:21,080 --> 00:21:21,080
 So we're competing with that as the Woodstock, Woodstock of AI.

412
00:21:21,080 --> 00:21:21,100
 So we're competing with that as the Woodstock, Woodstock of AI.

413
00:21:21,100 --> 00:21:21,160
 So we're competing with that as the Woodstock, Woodstock of AI.

414
00:21:21,160 --> 00:21:21,180
 So we're competing with that as the Woodstock, Woodstock of AI.

415
00:21:21,180 --> 00:21:21,220
 So we're competing with that as the Woodstock, Woodstock of AI.

416
00:21:21,220 --> 00:21:21,260
 So we're competing with that as the Woodstock, Woodstock of AI.

417
00:21:21,260 --> 00:21:21,340
 So we're competing with that as the Woodstock, Woodstock of AI.

418
00:21:21,340 --> 00:21:21,400
.

419
00:21:41,360 --> 00:22:11,340
 So we're competing with that as the Woodstock, Woodstock of AI.

420
00:22:11,340 --> 00:22:11,400
 So we're competing with that as the Woodstock, Woodstock of AI.

421
00:22:11,400 --> 00:22:11,440
 So we're competing with that as the Woodstock, Woodstock of AI.

422
00:22:11,440 --> 00:22:11,480
 So we're competing with that as the Woodstock, Woodstock of AI.

423
00:22:11,480 --> 00:22:11,520
 So we're competing with that as the Woodstock, Woodstock of AI.

424
00:22:11,520 --> 00:22:11,560
 So we're competing with that as the Woodstock, Woodstock of AI.

425
00:22:11,560 --> 00:22:11,580
 So we're competing with that as the Woodstock, Woodstock of AI.

426
00:22:11,580 --> 00:22:11,620
 So we're competing with that as the Woodstock, Woodstock of AI.

427
00:22:11,620 --> 00:22:11,640
 So we're competing with that as the Woodstock, Woodstock of AI.

428
00:22:11,640 --> 00:22:11,680
 So we're competing with that as the Woodstock, Woodstock of AI.

429
00:22:11,680 --> 00:22:11,740
 So we're competing with that as the Woodstock, Woodstock of AI.

430
00:22:11,740 --> 00:22:11,800
 So we're competing with that as the Woodstock, Woodstock of AI.

431
00:22:11,800 --> 00:22:11,800
 of AI.

432
00:22:11,840 --> 00:22:18,180
 So since the release of ChatGPT, right, and some people have said, OK, ChatGPT is the model to rule them all,

433
00:22:18,180 --> 00:22:23,020
 100,000 new models have been added on Hugging Face, right?

434
00:22:23,020 --> 00:22:27,880
 And obviously, companies, they don't train models just to train models, right?

435
00:22:27,880 --> 00:22:31,760
 They would prefer not to do it because it costs money to train models.

436
00:22:31,760 --> 00:22:41,760
 But the truth is, if you look at how AI is built, when you can build smaller, more specialized codes,

437
00:22:41,760 --> 00:22:48,540
 customized models for your use cases, they end up being cheaper, they end up being more efficient,

438
00:22:48,540 --> 00:22:52,640
 and they end up being better for your use case, right?

439
00:22:52,640 --> 00:22:59,820
 Just the same way every single technology company learned how to write code, right,

440
00:22:59,820 --> 00:23:05,700
 and to have a different code base than their competitors or than companies in other fields,

441
00:23:05,700 --> 00:23:08,840
 we're seeing the same thing for AI, right?

442
00:23:08,840 --> 00:23:11,740
 Every single company needs to train.

443
00:23:11,840 --> 00:23:18,040
 They need to train their own models, optimize their own models, learn how to run these models at scale.

444
00:23:18,040 --> 00:23:26,660
 Every single company needs to build their own ChatGPT because if they don't, they won't be able to differentiate.

445
00:23:26,660 --> 00:23:33,720
 They won't be able to create the unique technology value that they've been building for their customers,

446
00:23:33,720 --> 00:23:38,000
 and they'll lose control, right, if they start outsourcing it.

447
00:23:38,000 --> 00:23:40,820
 So that's what we're seeing on Hugging Face.

448
00:23:40,820 --> 00:23:41,720
 And in the economy.

449
00:23:41,720 --> 00:23:42,700
 And in the ecosystem as a whole.

450
00:23:42,700 --> 00:23:47,180
 It's back to this philosophy of don't just be a prompt tuner user, right?

451
00:23:47,180 --> 00:23:49,120
 Be a value creator with all of this.

452
00:23:49,120 --> 00:23:50,880
 So let's talk about our partnership for a minute.

453
00:23:50,880 --> 00:23:58,880
 Why are you excited about bringing the power of all of this community into Watson X in the context now of an enterprise,

454
00:23:58,880 --> 00:24:03,180
 you know, need and meeting the needs of our clients that are here listening?

455
00:24:03,180 --> 00:24:11,180
 Yeah, obviously Hugging Face and IBM share a lot of the same DNA, right, around open source.

456
00:24:11,180 --> 00:24:18,660
 Open platform, kind of like providing extensible tools for companies.

457
00:24:18,660 --> 00:24:26,780
 For me, one of the most iconic collaboration partnership of the last decade is IBM plus Red Hat.

458
00:24:26,780 --> 00:24:29,720
 And hopefully we're just at the beginning of it.

459
00:24:29,720 --> 00:24:34,460
 But with this collaboration, we can do the same thing for AI.

460
00:24:34,460 --> 00:24:40,460
 I think with this integration between Watson X and Hugging Face,

461
00:24:40,460 --> 00:24:47,080
 you kind of like get the best of both worlds in the sense that you get the cutting edge and the community

462
00:24:47,080 --> 00:24:52,540
 and the numbers of models, data sets, apps of the Hugging Face ecosystem.

463
00:24:52,540 --> 00:24:58,860
 And you get the security and supports of IBM, right?

464
00:24:58,860 --> 00:25:02,380
 For example, you mentioned, we mentioned all the models.

465
00:25:02,380 --> 00:25:09,360
 The IBM consultants can help you to pick the right models for you at the time

466
00:25:09,360 --> 00:25:10,440
 that is going to make the decision.

467
00:25:10,540 --> 00:25:12,380
 And that makes sense for your company.

468
00:25:12,380 --> 00:25:18,080
 So you really get kind of like the perfect mix to get to what we were saying,

469
00:25:18,080 --> 00:25:22,680
 meaning every one of you being able to build your own internal chat GPT.

470
00:25:22,680 --> 00:25:25,400
 So tell us, this is just great.

471
00:25:25,400 --> 00:25:27,900
 I'm just delighted about those opportunities.

472
00:25:27,900 --> 00:25:31,100
 And so tell us a little bit about what's next for Hugging Face.

473
00:25:31,100 --> 00:25:33,900
 When you look over the next year or so, what excites you the most?

474
00:25:33,900 --> 00:25:37,480
 Many, many exciting things for us.

475
00:25:37,480 --> 00:25:40,420
 We've seen a lot of adoption.

476
00:25:40,420 --> 00:25:46,720
 A lot of companies using us for text, for audio, for image.

477
00:25:46,720 --> 00:25:51,520
 And now we're starting to see that expand to other domains.

478
00:25:51,520 --> 00:25:55,080
 For example, we're seeing a lot of video right now.

479
00:25:55,080 --> 00:25:57,540
 We're seeing a lot of recommender systems.

480
00:25:57,540 --> 00:25:59,600
 We're seeing a lot of time series.

481
00:25:59,600 --> 00:26:02,680
 We're starting a lot of biology, chemistry.

482
00:26:02,680 --> 00:26:04,680
 We're really excited about it.

483
00:26:04,680 --> 00:26:09,960
 We think ultimately AI is the new default to build all features,

484
00:26:10,400 --> 00:26:12,440
 all workflows, all products.

485
00:26:12,440 --> 00:26:15,400
 It's kind of like the new default to build all tech.

486
00:26:15,400 --> 00:26:20,400
 So we're excited for this expansion to other domains.

487
00:26:20,400 --> 00:26:27,200
 Also, we're seeing a lot of work around chaining different models.

488
00:26:27,200 --> 00:26:30,580
 And in fact, at Hugging Face, we released today Transformers Agents,

489
00:26:30,580 --> 00:26:36,440
 which is a way to chain different models to build more complex systems

490
00:26:36,440 --> 00:26:40,380
 that are achieving kind of like better capabilities.

491
00:26:40,380 --> 00:26:43,380
 These are some of the things that we're the most excited about.

492
00:26:43,380 --> 00:26:44,380
 So a lot there.

493
00:26:44,380 --> 00:26:45,380
 So thank you, Clem.

494
00:26:45,380 --> 00:26:46,380
 Thank you so much.

495
00:26:46,380 --> 00:26:47,380
 Thank you so much.

496
00:26:47,380 --> 00:26:48,380
 And congratulations.

497
00:26:48,380 --> 00:26:49,380
 Thanks.

498
00:26:49,380 --> 00:26:50,380
 Thank you.

499
00:26:50,380 --> 00:27:00,380
 So, well, you saw how the platform works to enable the foundation model creation workflow end-to-end.

500
00:27:00,380 --> 00:27:02,380
 And we talked about data.

501
00:27:02,380 --> 00:27:10,360
 We talked about model architectures, the compute infrastructure, the models themselves, the importance of modeling.

502
00:27:10,360 --> 00:27:12,360
 So we're going to start off the open community.

503
00:27:12,360 --> 00:27:17,360
 So now let me show you how to use and how you would experience WatsonX.

504
00:27:17,360 --> 00:27:21,360
 And we're going to go inside the studio, inside WatsonX.ai.

505
00:27:21,360 --> 00:27:30,360
 And from the landing page, you can choose to prompt models, to fine-tune models or deploy and manage your deployed models.

506
00:27:30,360 --> 00:27:35,360
 So here's an example of how you can use the prompt lab to do a summarization task.

507
00:27:35,360 --> 00:27:40,340
 You give the model the text as a prompt, and the model summarizes it for you.

508
00:27:40,340 --> 00:27:49,340
 In the case of a customer care interaction, it gives you the customer problem and the resolution according to the transcript of the interaction.

509
00:27:49,340 --> 00:27:58,340
 In the tuning studio, as we saw before, you can set the parameters of the type of tuning that you want to do and the base model, and you can add your data.

510
00:27:58,340 --> 00:28:05,340
 The studio gives you detailed stats of the tuning process and allows you to deploy the tuned model in your application.

511
00:28:05,340 --> 00:28:07,340
 It's that simple.

512
00:28:07,340 --> 00:28:10,320
 We took the complexity of the process away.

513
00:28:10,320 --> 00:28:14,320
 You only need to worry about creating value for your business.

514
00:28:14,320 --> 00:28:18,320
 And here are some of our current AI value creators.

515
00:28:18,320 --> 00:28:24,320
 SAP will use IBM Watson capabilities to power its digital assistant in their SAP solutions.

516
00:28:24,320 --> 00:28:31,320
 You've been hearing about Red Hat, how it's embedding IBM Watson code assistant into the Ansible automation platform.

517
00:28:31,320 --> 00:28:38,320
 BBBA is bringing their enterprise data to use with their own foundation model for natural language.

518
00:28:38,320 --> 00:28:40,300
 Moderna is supplying IBM's foundation model for natural language.

519
00:28:40,300 --> 00:28:44,300
 Microsoft is using cloud-based AI automation models to help predict potential mRNA medicines.

520
00:28:44,300 --> 00:28:54,300
 NASA is using our language models together with US spatial models we've created together to improve our scientific understanding and response to Earth and climate-related issues.

521
00:28:54,300 --> 00:29:03,300
 And Wix is using foundation models to gain novel insights for customer care as they meet the needs of their customers.

522
00:29:03,300 --> 00:29:10,280
 So what I encourage you is to join them and embrace the age of value creation with AI.

523
00:29:10,280 --> 00:29:16,280
 So I stood on a stage just like this, closing Think.

524
00:29:16,280 --> 00:29:22,280
 And I shared with all of the attendees that what was next in AI was foundation models.

525
00:29:22,280 --> 00:29:28,280
 And maybe at the time it seemed a little bit abstract and, you know, sort of like this intellectual disposition about where things were going.

526
00:29:28,280 --> 00:29:31,280
 But boy, what a year it has been.

527
00:29:31,280 --> 00:29:35,280
 And it has been a big year for AI at IBM.

528
00:29:35,280 --> 00:29:40,260
 So as we close our event this year, let me remind you of all the things

529
00:29:40,260 --> 00:29:42,260
 that we have created and announced.

530
00:29:42,260 --> 00:29:51,260
 We've announced WatsonX, a comprehensive platform that allows you to create and govern AI in real time so that you can move with urgency and capture this moment.

531
00:29:51,260 --> 00:30:00,260
 We announced a set, a family of foundation models, including IBM models, open community models, and how you can even create your own models.

532
00:30:00,260 --> 00:30:10,240
 We announced our data model factory, using petabytes of data across multiple domains to create trillions of tokens to create our family of foundation models.

533
00:30:10,240 --> 00:30:20,240
 And show how the factory continuously updates them when conditions change and brings a regular cadence of models to ensure proper governance.

534
00:30:20,240 --> 00:30:33,240
 We told you about products where we have infused our foundation models, over 15 of them, including digital labor, Red Hat, products like Ansible Automation Platform, our partner products like SAP Solutions.

535
00:30:33,240 --> 00:30:40,220
 We announced important collaborations to advance AI and bring it to the enterprise, Hugging Face and longstanding collaborations

536
00:30:40,220 --> 00:30:42,220
 and initiatives like PyTorch and Ray.

537
00:30:42,220 --> 00:30:48,220
 We showed you some of the organizations that have become AI value creators with us.

538
00:30:48,220 --> 00:30:57,220
 We're bringing IBM Vela, our cloud-native AI supercomputer, to train foundation models with bare-metal performance while giving us the flexibility of the cloud.

539
00:30:57,220 --> 00:31:01,220
 And we announced that we're making it available as a service.

540
00:31:01,220 --> 00:31:05,220
 Last year, we launched the Telum in C16.

541
00:31:05,220 --> 00:31:10,200
 It's an engineering marvel, and IBM's first processor to have the ability

542
00:31:10,200 --> 00:31:13,200
 to process on-chip accelerators for AI inferencing.

543
00:31:13,200 --> 00:31:18,200
 It can process 300 billion inferences per day with one millisecond latencies.

544
00:31:18,200 --> 00:31:29,200
 This means that now you can infuse AI into every transaction in C16 for applications like fraud detection and others in real time.

545
00:31:29,200 --> 00:31:40,180
 Using the same core architecture as Telum, we built the IBM Research AIU, which is optimized to give superior performance for foundation models and enable with the Red Hat software.

546
00:31:40,180 --> 00:31:49,180
 And at IBM Research, we are incubating powerful AIU systems designed and optimized for enterprise AI inference and tuning.

547
00:31:49,180 --> 00:32:00,180
 So, a truly fantastic year, and this is just the start of all the amazing things that we're building and developing for you and that we will be sharing with you in the coming years.

548
00:32:00,180 --> 00:32:06,180
 So today, more than ever before, it's important to have a business strategy in AI.

549
00:32:06,180 --> 00:32:10,160
 And in closing, as you think about how to harness AI,

550
00:32:10,160 --> 00:32:13,160
 how to build foundation models for your business,

551
00:32:13,160 --> 00:32:17,160
 let me offer you some tips to consider.

552
00:32:17,160 --> 00:32:20,160
 First, act with urgency.

553
00:32:20,160 --> 00:32:23,160
 This is a transformative moment in technology.

554
00:32:23,160 --> 00:32:26,160
 Be bold and capture the moment.

555
00:32:26,160 --> 00:32:29,160
 Second, be a value creator.

556
00:32:29,160 --> 00:32:33,160
 Build foundation models on your data and under your control.

557
00:32:33,160 --> 00:32:36,160
 They will become your most valuable asset.

558
00:32:36,160 --> 00:32:40,140
 Don't outsource that and don't reduce your AI strategy

559
00:32:40,140 --> 00:32:42,140
 to an API call.

560
00:32:42,140 --> 00:32:45,140
 Third, bet on community.

561
00:32:45,140 --> 00:32:50,140
 Bet on the energy and the ingenuity of the open AI community.

562
00:32:50,140 --> 00:32:54,140
 One model, I guarantee you, will not rule them all.

563
00:32:54,140 --> 00:32:56,140
 Run everywhere efficiently.

564
00:32:56,140 --> 00:33:03,140
 Optimize for performance, latency, and cost by building with open hybrid technologies.

565
00:33:03,140 --> 00:33:06,140
 And finally, be responsible.

566
00:33:06,140 --> 00:33:08,140
 I can't stress this enough.

567
00:33:08,140 --> 00:33:10,120
 Everything I've mentioned is useless.

568
00:33:10,120 --> 00:33:13,120
 Unless you build responsibly, transparently,

569
00:33:13,120 --> 00:33:18,120
 and put governance into the heart of your AI lifecycle.

570
00:33:18,120 --> 00:33:24,120
 Continuously govern the data you use and the AI you deploy.

571
00:33:24,120 --> 00:33:27,120
 And co-create with trusted partners.

572
00:33:27,120 --> 00:33:31,120
 Trust is your ultimate license to operate.

573
00:33:31,120 --> 00:33:35,120
 If you map your AI business strategy against these recommendations,

574
00:33:35,120 --> 00:33:40,100
 you will be in a prime position to do amazing things with foundation models

575
00:33:40,100 --> 00:33:42,100
 and generative AI.

576
00:33:42,100 --> 00:33:47,100
 We have built WatsonX so that you can do just that.

577
00:33:47,100 --> 00:33:49,100
 And I hope you join us.

578
00:33:49,100 --> 00:33:54,100
 Because we cannot wait to get started on this journey with you.

579
00:33:54,100 --> 00:33:55,100
 Thank you.

580
00:33:55,100 --> 00:33:56,100
 Thank you.

581
00:33:56,100 --> 00:33:57,100
 Thank you.

582
00:33:57,100 --> 00:33:58,100
 Thank you.

583
00:33:58,100 --> 00:33:58,100
 Thank you.

584
00:33:58,100 --> 00:33:59,100
 Thank you.

585
00:33:59,100 --> 00:33:59,100
 Thank you.

586
00:33:59,100 --> 00:34:00,100
 Thank you.

587
00:34:00,100 --> 00:34:01,100
 Thank you.

588
00:34:01,100 --> 00:34:02,100
 Thank you.

589
00:34:02,100 --> 00:34:03,100
 Thank you.

590
00:34:03,100 --> 00:34:04,100
 Thank you.

591
00:34:04,100 --> 00:34:04,100
 Thank you.

592
00:34:04,100 --> 00:34:07,100
 ♪ ♪

593
00:34:07,100 --> 00:34:12,100
 ♪ ♪

594
00:34:12,100 --> 00:34:17,100
 ♪ ♪

595
00:34:17,100 --> 00:34:20,100
 ♪ ♪

